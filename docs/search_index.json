[["index.html", "Statistics and Machine Learning Notes Chapter 1 R notes 1.1 Tables", " Statistics and Machine Learning Notes Duzhe Wang (duzhe.stat@gmail.com) 2023-02-04 Chapter 1 R notes 1.1 Tables 1.1.1 How do we print lm results in Rmarkdown html/pdf? https://zief0002.github.io/book-8252/pretty-printing-tables-in-markdown.html https://cran.r-project.org/web/packages/broom/vignettes/broom.html https://stackoverflow.com/questions/55712224/in-bookdown-avoid-wide-tables-to-be-cut-off library(broom) library(tidyverse) library(kableExtra) lm(mpg ~ wt, mtcars) %&gt;% tidy() %&gt;% knitr::kable() term estimate std.error statistic p.value (Intercept) 37.285126 1.877627 19.857575 0 wt -5.344472 0.559101 -9.559044 0 lm(mpg ~ wt, mtcars) %&gt;% glance() %&gt;% knitr::kable() %&gt;% kable_styling() %&gt;% scroll_box(width = &quot;100%&quot;, box_css = &quot;border: 0px;&quot;) r.squared adj.r.squared sigma statistic p.value df logLik AIC BIC deviance df.residual nobs 0.7528328 0.7445939 3.045882 91.37533 0 1 -80.01471 166.0294 170.4266 278.3219 30 32 "],["subgroup-identification.html", "Chapter 2 Subgroup identification", " Chapter 2 Subgroup identification Subgroup analysis tools: https://biopharmnet.com/subgroup-analysis/ "],["individualized-treatment-rules.html", "Chapter 3 Individualized treatment rules 3.1 Books", " Chapter 3 Individualized treatment rules 3.1 Books Dynamic treatment regimes: statistical methods for precision medicine "],["interaction.html", "Chapter 4 Interaction 4.1 Example 1 4.2 Example 2", " Chapter 4 Interaction 4.1 Example 1 df=data.frame(y=c(3, 3, 3, 7, 8, 5, 6, 3, 5, 7), trt=as.factor(c(&quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;)), center=as.factor(c(1, 1,1, 2, 2, 1, 1, 2,2, 2))) df ## y trt center ## 1 3 A 1 ## 2 3 A 1 ## 3 3 A 1 ## 4 7 A 2 ## 5 8 A 2 ## 6 5 B 1 ## 7 6 B 1 ## 8 3 B 2 ## 9 5 B 2 ## 10 7 B 2 The following three models are same. fit1=lm(y~trt*center, data=df) fit2=lm(y~trt+center+trt*center, data=df) fit3=lm(y~trt+center+trt:center, data=df) summary(fit1) ## ## Call: ## lm(formula = y ~ trt * center, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.000 -0.375 0.000 0.375 2.000 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.0000 0.7071 4.243 0.00542 ** ## trtB 2.5000 1.1180 2.236 0.06671 . ## center2 4.5000 1.1180 4.025 0.00692 ** ## trtB:center2 -5.0000 1.5811 -3.162 0.01951 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.225 on 6 degrees of freedom ## Multiple R-squared: 0.7353, Adjusted R-squared: 0.6029 ## F-statistic: 5.556 on 3 and 6 DF, p-value: 0.0363 summary(fit2) ## ## Call: ## lm(formula = y ~ trt + center + trt * center, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.000 -0.375 0.000 0.375 2.000 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.0000 0.7071 4.243 0.00542 ** ## trtB 2.5000 1.1180 2.236 0.06671 . ## center2 4.5000 1.1180 4.025 0.00692 ** ## trtB:center2 -5.0000 1.5811 -3.162 0.01951 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.225 on 6 degrees of freedom ## Multiple R-squared: 0.7353, Adjusted R-squared: 0.6029 ## F-statistic: 5.556 on 3 and 6 DF, p-value: 0.0363 summary(fit3) ## ## Call: ## lm(formula = y ~ trt + center + trt:center, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.000 -0.375 0.000 0.375 2.000 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.0000 0.7071 4.243 0.00542 ** ## trtB 2.5000 1.1180 2.236 0.06671 . ## center2 4.5000 1.1180 4.025 0.00692 ** ## trtB:center2 -5.0000 1.5811 -3.162 0.01951 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.225 on 6 degrees of freedom ## Multiple R-squared: 0.7353, Adjusted R-squared: 0.6029 ## F-statistic: 5.556 on 3 and 6 DF, p-value: 0.0363 model.matrix(fit1) ## (Intercept) trtB center2 trtB:center2 ## 1 1 0 0 0 ## 2 1 0 0 0 ## 3 1 0 0 0 ## 4 1 0 1 0 ## 5 1 0 1 0 ## 6 1 1 0 0 ## 7 1 1 0 0 ## 8 1 1 1 1 ## 9 1 1 1 1 ## 10 1 1 1 1 ## attr(,&quot;assign&quot;) ## [1] 0 1 2 3 ## attr(,&quot;contrasts&quot;) ## attr(,&quot;contrasts&quot;)$trt ## [1] &quot;contr.treatment&quot; ## ## attr(,&quot;contrasts&quot;)$center ## [1] &quot;contr.treatment&quot; model.matrix(fit2) ## (Intercept) trtB center2 trtB:center2 ## 1 1 0 0 0 ## 2 1 0 0 0 ## 3 1 0 0 0 ## 4 1 0 1 0 ## 5 1 0 1 0 ## 6 1 1 0 0 ## 7 1 1 0 0 ## 8 1 1 1 1 ## 9 1 1 1 1 ## 10 1 1 1 1 ## attr(,&quot;assign&quot;) ## [1] 0 1 2 3 ## attr(,&quot;contrasts&quot;) ## attr(,&quot;contrasts&quot;)$trt ## [1] &quot;contr.treatment&quot; ## ## attr(,&quot;contrasts&quot;)$center ## [1] &quot;contr.treatment&quot; model.matrix(fit3) ## (Intercept) trtB center2 trtB:center2 ## 1 1 0 0 0 ## 2 1 0 0 0 ## 3 1 0 0 0 ## 4 1 0 1 0 ## 5 1 0 1 0 ## 6 1 1 0 0 ## 7 1 1 0 0 ## 8 1 1 1 1 ## 9 1 1 1 1 ## 10 1 1 1 1 ## attr(,&quot;assign&quot;) ## [1] 0 1 2 3 ## attr(,&quot;contrasts&quot;) ## attr(,&quot;contrasts&quot;)$trt ## [1] &quot;contr.treatment&quot; ## ## attr(,&quot;contrasts&quot;)$center ## [1] &quot;contr.treatment&quot; Model: \\[y_i=\\beta_0+\\beta_1 I(i\\in \\text{trtB})+\\beta_2 I(i\\in \\text{center2})+\\beta_3 I(i \\in \\text{trtB and center2})+\\varepsilon_i \\] trtA &amp; center2: \\(\\beta_0+\\beta_2\\) trtB &amp; center2: \\(\\beta_0+\\beta_1+\\beta_2+\\beta_3\\) difference of trt effects conditioning on center2: \\(\\beta_1+\\beta_3\\) trtA &amp; center1: \\(\\beta_0\\) trtB &amp; center1: \\(\\beta_0+\\beta_1\\) difference of trt effects conditioning on center1: \\(\\beta_1\\) Therefore, there is an interaction between trt and center 4.2 Example 2 set.seed(12) f1 &lt;- gl(n = 2, k = 30, labels = c(&quot;Low&quot;, &quot;High&quot;)) ## generate factor levels f2 &lt;- as.factor(rep(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), times = 20)) modmat &lt;- model.matrix(~f1 * f2, data.frame(f1 = f1, f2 = f2)) ## make the design matrix coeff &lt;- c(1, 3, -2, -4, 1, -1.2) y &lt;- rnorm(n = 60, mean = modmat %*% coeff, sd = 0.1) dat &lt;- data.frame(y = y, f1 = f1, f2 = f2) summary(lm(y ~ f1 * f2)) ## ## Call: ## lm(formula = y ~ f1 * f2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.199479 -0.063752 -0.001089 0.058162 0.222229 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.97849 0.02865 34.15 &lt;2e-16 *** ## f1High 3.00306 0.04052 74.11 &lt;2e-16 *** ## f2B -1.97878 0.04052 -48.83 &lt;2e-16 *** ## f2C -4.00206 0.04052 -98.77 &lt;2e-16 *** ## f1High:f2B 0.98924 0.05731 17.26 &lt;2e-16 *** ## f1High:f2C -1.16620 0.05731 -20.35 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.09061 on 54 degrees of freedom ## Multiple R-squared: 0.9988, Adjusted R-squared: 0.9987 ## F-statistic: 8785 on 5 and 54 DF, p-value: &lt; 2.2e-16 model.matrix(lm(y ~ f1 * f2)) ## (Intercept) f1High f2B f2C f1High:f2B f1High:f2C ## 1 1 0 0 0 0 0 ## 2 1 0 1 0 0 0 ## 3 1 0 0 1 0 0 ## 4 1 0 0 0 0 0 ## 5 1 0 1 0 0 0 ## 6 1 0 0 1 0 0 ## 7 1 0 0 0 0 0 ## 8 1 0 1 0 0 0 ## 9 1 0 0 1 0 0 ## 10 1 0 0 0 0 0 ## 11 1 0 1 0 0 0 ## 12 1 0 0 1 0 0 ## 13 1 0 0 0 0 0 ## 14 1 0 1 0 0 0 ## 15 1 0 0 1 0 0 ## 16 1 0 0 0 0 0 ## 17 1 0 1 0 0 0 ## 18 1 0 0 1 0 0 ## 19 1 0 0 0 0 0 ## 20 1 0 1 0 0 0 ## 21 1 0 0 1 0 0 ## 22 1 0 0 0 0 0 ## 23 1 0 1 0 0 0 ## 24 1 0 0 1 0 0 ## 25 1 0 0 0 0 0 ## 26 1 0 1 0 0 0 ## 27 1 0 0 1 0 0 ## 28 1 0 0 0 0 0 ## 29 1 0 1 0 0 0 ## 30 1 0 0 1 0 0 ## 31 1 1 0 0 0 0 ## 32 1 1 1 0 1 0 ## 33 1 1 0 1 0 1 ## 34 1 1 0 0 0 0 ## 35 1 1 1 0 1 0 ## 36 1 1 0 1 0 1 ## 37 1 1 0 0 0 0 ## 38 1 1 1 0 1 0 ## 39 1 1 0 1 0 1 ## 40 1 1 0 0 0 0 ## 41 1 1 1 0 1 0 ## 42 1 1 0 1 0 1 ## 43 1 1 0 0 0 0 ## 44 1 1 1 0 1 0 ## 45 1 1 0 1 0 1 ## 46 1 1 0 0 0 0 ## 47 1 1 1 0 1 0 ## 48 1 1 0 1 0 1 ## 49 1 1 0 0 0 0 ## 50 1 1 1 0 1 0 ## 51 1 1 0 1 0 1 ## 52 1 1 0 0 0 0 ## 53 1 1 1 0 1 0 ## 54 1 1 0 1 0 1 ## 55 1 1 0 0 0 0 ## 56 1 1 1 0 1 0 ## 57 1 1 0 1 0 1 ## 58 1 1 0 0 0 0 ## 59 1 1 1 0 1 0 ## 60 1 1 0 1 0 1 ## attr(,&quot;assign&quot;) ## [1] 0 1 2 2 3 3 ## attr(,&quot;contrasts&quot;) ## attr(,&quot;contrasts&quot;)$f1 ## [1] &quot;contr.treatment&quot; ## ## attr(,&quot;contrasts&quot;)$f2 ## [1] &quot;contr.treatment&quot; Model: \\[y_i=\\beta_0+\\beta_1I(i\\in \\text{f1High})+\\beta_2I(i\\in \\text{f2B})+\\beta_3I(I\\in \\text{f2C})+ \\\\ \\beta_4 I(i\\in \\text{f1High and f2B})+\\beta_5 I(i\\in\\text{f1High and f2C})+\\varepsilon_i \\] f1 high and f2 A: \\(\\beta_0+\\beta_1\\) f1 high and f2 B: \\(\\beta_0+\\beta_1+\\beta_2+\\beta_4\\) f1 high and f2 C: \\(\\beta_0+\\beta_1+\\beta_3+\\beta_5\\) f1 low and f2 A: \\(\\beta_0\\) f1 low and f2 B: \\(\\beta_0+\\beta_2\\) f1 low and f2 C: \\(\\beta_0+\\beta_3\\) See more at https://rpubs.com/hughes/15353 "],["least-squares-mean.html", "Chapter 5 Least squares mean 5.1 Reference 5.2 Pigs data example 5.3 Iris data example", " Chapter 5 Least squares mean 5.1 Reference https://cran.r-project.org/web/packages/emmeans/vignettes/basics.html https://cran.r-project.org/web/packages/emmeans/vignettes/comparisons.html 5.2 Pigs data example library(emmeans) library(tidyverse) with(pigs, interaction.plot(percent, source, conc)) pigs%&gt;%group_by(percent)%&gt;%summarise(marginalmean=mean(conc)) ## # A tibble: 4 × 2 ## percent marginalmean ## &lt;dbl&gt; &lt;dbl&gt; ## 1 9 32.7 ## 2 12 38.0 ## 3 15 40.1 ## 4 18 39.9 pigs%&gt;%group_by(percent, source)%&gt;%summarise(mean(conc)) ## `summarise()` has grouped output by &#39;percent&#39;. You can override using the `.groups` argument. ## # A tibble: 12 × 3 ## # Groups: percent [4] ## percent source `mean(conc)` ## &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 9 fish 25.8 ## 2 9 soy 34.6 ## 3 9 skim 35.4 ## 4 12 fish 30.9 ## 5 12 soy 39.6 ## 6 12 skim 43.5 ## 7 15 fish 31.2 ## 8 15 soy 39.2 ## 9 15 skim 50.4 ## 10 18 fish 32.3 ## 11 18 soy 42.9 ## 12 18 skim 59.8 lm1=lm(conc ~ source + factor(percent), data = pigs) summary(lm1) ## ## Call: ## lm(formula = conc ~ source + factor(percent), data = pigs) ## ## Residuals: ## Min 1Q Median 3Q Max ## -7.887 -2.590 -1.090 2.023 12.300 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 23.303 2.364 9.859 9.99e-10 *** ## sourcesoy 9.474 2.334 4.059 0.000485 *** ## sourceskim 15.584 2.388 6.526 1.17e-06 *** ## factor(percent)12 6.355 2.472 2.570 0.017101 * ## factor(percent)15 8.312 2.633 3.156 0.004414 ** ## factor(percent)18 11.625 2.981 3.899 0.000722 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 5.076 on 23 degrees of freedom ## Multiple R-squared: 0.6997, Adjusted R-squared: 0.6344 ## F-statistic: 10.72 on 5 and 23 DF, p-value: 2.071e-05 lsm=emmeans(lm1, specs = &quot;source&quot;) lsm ## source emmean SE df lower.CL upper.CL ## fish 29.9 1.62 23 26.5 33.2 ## soy 39.4 1.65 23 35.9 42.8 ## skim 45.5 1.74 23 41.9 49.1 ## ## Results are averaged over the levels of: percent ## Confidence level used: 0.95 pairs(lsm) ## contrast estimate SE df t.ratio p.value ## fish - soy -9.47 2.33 23 -4.059 0.0014 ## fish - skim -15.58 2.39 23 -6.526 &lt;.0001 ## soy - skim -6.11 2.34 23 -2.613 0.0398 ## ## Results are averaged over the levels of: percent ## P value adjustment: tukey method for comparing a family of 3 estimates Check how estimated marginal mean is calculated: lm1coef=as.vector(coef(lm1)) # balanced design lm1coef[1]+(lm1coef[4]+lm1coef[5]+lm1coef[6])/4 ## [1] 29.87661 lm1coef[1]+lm1coef[2]+(lm1coef[4]+lm1coef[5]+lm1coef[6])/4 ## [1] 39.35038 lm1coef[1]+lm1coef[3]+(lm1coef[4]+lm1coef[5]+lm1coef[6])/4 ## [1] 45.46034 Add one more column in pigs dataset set.seed(123) pigs$normalrv=rnorm(nrow(pigs), mean = 10, sd = 1) lm2=lm(conc ~ source + factor(percent) + normalrv, data = pigs) summary(lm2) ## ## Call: ## lm(formula = conc ~ source + factor(percent) + normalrv, data = pigs) ## ## Residuals: ## Min 1Q Median 3Q Max ## -8.7188 -3.0119 -0.6837 2.5303 10.2160 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.497 11.927 0.293 0.772137 ## sourcesoy 9.613 2.246 4.280 0.000305 *** ## sourceskim 17.241 2.497 6.905 6.2e-07 *** ## factor(percent)12 6.146 2.381 2.581 0.017044 * ## factor(percent)15 7.517 2.576 2.918 0.007976 ** ## factor(percent)18 13.224 3.019 4.380 0.000239 *** ## normalrv 1.940 1.147 1.692 0.104811 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.882 on 22 degrees of freedom ## Multiple R-squared: 0.7342, Adjusted R-squared: 0.6618 ## F-statistic: 10.13 on 6 and 22 DF, p-value: 2.085e-05 emmeans(lm2, specs = &quot;source&quot;) ## source emmean SE df lower.CL upper.CL ## fish 29.4 1.58 22 26.2 32.7 ## soy 39.1 1.60 22 35.7 42.4 ## skim 46.7 1.82 22 42.9 50.5 ## ## Results are averaged over the levels of: percent ## Confidence level used: 0.95 Model: \\[y_i=\\alpha_0+\\alpha_1 I(S_i=\\text{soy})+\\alpha_2 I(S_i=\\text{skim})+\\alpha_3 I(F_i=12)+\\alpha_4 I(F_i=15)+ \\\\ \\alpha_5 I(F_i=18)+ \\alpha_6 X_i\\] Assume a balanced design, we have \\[\\begin{equation*} \\begin{split} E(y_i \\mid S_i=\\text{fish})=E_{X}\\left\\{\\frac{1}{4}\\left[E(y_i \\mid S_i=\\text{fish}, F_i=9,X)+E(y_i \\mid S_i=\\text{fish}, F_i=12,X)+ \\\\ E(y_i \\mid S_i=\\text{fish}, F_i= 15,X)+E(y_i \\mid S_i=\\text{fish}, F_i=18,X)\\right]\\right\\} \\end{split} \\end{equation*}\\] alpha0=as.vector(coef(lm2))[1] alpha1=as.vector(coef(lm2))[2] alpha2=as.vector(coef(lm2))[3] alpha3=as.vector(coef(lm2))[4] alpha4=as.vector(coef(lm2))[5] alpha5=as.vector(coef(lm2))[6] alpha6=as.vector(coef(lm2))[7] meanX=mean(pigs$normalrv) alpha0+(alpha3+alpha4+alpha5)/4+alpha6*meanX ## [1] 29.44408 alpha0+alpha1+(alpha3+alpha4+alpha5)/4+alpha6*meanX ## [1] 39.0572 alpha0+alpha2+(alpha3+alpha4+alpha5)/4+alpha6*meanX ## [1] 46.68497 5.3 Iris data example # make virginica the reference group iris &lt;- iris %&gt;% mutate( Species = forcats::fct_relevel(Species, &#39;virginica&#39;) ) m1 &lt;- lm( Sepal.Width ~ Sepal.Length + Species, data=iris ) # Parallel Lines summary(m1) ## ## Call: ## lm(formula = Sepal.Width ~ Sepal.Length + Species, data = iris) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.95096 -0.16522 0.00171 0.18416 0.72918 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.66899 0.30776 2.174 0.0313 * ## Sepal.Length 0.34988 0.04630 7.557 4.19e-12 *** ## Speciessetosa 1.00751 0.09331 10.798 &lt; 2e-16 *** ## Speciesversicolor 0.02412 0.06521 0.370 0.7120 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.289 on 146 degrees of freedom ## Multiple R-squared: 0.5693, Adjusted R-squared: 0.5604 ## F-statistic: 64.32 on 3 and 146 DF, p-value: &lt; 2.2e-16 emmeans(m1, specs = &quot;Species&quot;) ## Species emmean SE df lower.CL upper.CL ## virginica 2.71 0.0535 146 2.61 2.82 ## setosa 3.72 0.0563 146 3.61 3.83 ## versicolor 2.74 0.0411 146 2.66 2.82 ## ## Confidence level used: 0.95 Calculate the estimated marginal mean as follows: Model: \\(y_i=\\alpha_0+\\alpha_1X_i+\\alpha_2 I(S_i=\\text{setosa})+\\alpha_3 I(S_i=\\text{versicolor})\\) \\(E(y_i \\mid S_i=\\text{virginica})=E_{X}(E(y_i \\mid S_i=\\text{virginica}, X))=\\alpha_0+\\alpha_1 E(X)\\) \\(E(y_i \\mid S_i=\\text{setosa})=E_{X}(E(y_i \\mid S_i=\\text{setosa}, X))=\\alpha_0+\\alpha_1 E(X)+\\alpha_2\\) \\(E(y_i \\mid S_i=\\text{versicolor})=E_{X}(E(y_i \\mid S_i=\\text{versicolor}, X))=\\alpha_0+\\alpha_1E(X)+\\alpha_3\\) alpha0=as.vector(coef(m1))[1] alpha1=as.vector(coef(m1))[2] alpha2=as.vector(coef(m1))[3] alpha3=as.vector(coef(m1))[4] meanX=mean(iris$Sepal.Length) alpha0+alpha1*meanX ## [1] 2.713456 alpha0+alpha1*meanX+alpha2 ## [1] 3.720966 alpha0+alpha1*meanX+alpha3 ## [1] 2.737578 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
